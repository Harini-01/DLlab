import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torchvision.datasets import MNIST
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt

# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Transforms
transform = transforms.Compose([
    transforms.ToTensor()
])

# Load MNIST
train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)

# Blurring function (downsample + upsample)
def blur_images(batch):
    down = F.interpolate(batch, size=(14, 14), mode='bilinear')
    up = F.interpolate(down, size=(28, 28), mode='bilinear')
    return up

# Dataloaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)

# U-Net like model
class SimpleUNet(nn.Module):
    def __init__(self):
        super(SimpleUNet, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.middle = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 1, kernel_size=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.middle(x)
        x = self.decoder(x)
        return x

# Model, loss, optimizer
model = SimpleUNet().to(device)
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters())

# Training loop
model.train()
for epoch in range(5):
    total_loss = 0
    for images, _ in train_loader:
        images = images.to(device)
        blurred = blur_images(images).to(device)

        outputs = model(blurred)
        loss = criterion(outputs, images)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}")

# Evaluation and visualization
model.eval()
with torch.no_grad():
    images, _ = next(iter(test_loader))
    images = images.to(device)
    blurred = blur_images(images)
    predicted = model(blurred)

    # Display
    for i in range(5):
        plt.figure(figsize=(8, 2))
        titles = ["Blurry Input", "Ground Truth", "Predicted"]
        imgs = [blurred[i], images[i], predicted[i]]
        for j in range(3):
            plt.subplot(1, 3, j + 1)
            plt.title(titles[j])
            plt.imshow(imgs[j].cpu().squeeze(), cmap='gray')
            plt.axis('off')
        plt.show()
